{"cells":[{"cell_type":"markdown","id":"f978c112-9fe0-44cb-a3ff-3dd08a6e991e","metadata":{"id":"f978c112-9fe0-44cb-a3ff-3dd08a6e991e"},"source":["# Word2Vec\n","\n","Word2Vec is a popular technique in natural language processing (NLP) for learning word embeddings, which are continuous vector representations of words in a high-dimensional space. Word embeddings capture semantic and syntactic relationships between words and are a fundamental component of many NLP applications. Word2Vec was introduced by researchers at Google in a pair of papers published in 2013.\n","\n","The name \"Word2Vec\" is derived from its primary function: it transforms words into vectors.\n","\n","\n","Word2Vec has been widely adopted in various NLP applications, including:\n","\n","- **Text Classification**: Word embeddings serve as features for training classifiers to categorize text into different classes.\n","- **Information Retrieval**: Word2Vec can be used to represent documents or queries in vector space, making it easier to find similar documents.\n","- **Named Entity Recognition (NER)**: Embeddings help recognize named entities and their types in text.\n","- **Machine Translation**: Word embeddings enable better translation models by capturing semantic relationships between words in different languages.\n","- **Question Answering**: Word2Vec embeddings are used to match questions with relevant answers.\n","- **Recommendation Systems**: They are used to recommend products or content based on users' preferences and content similarity.\n","\n","\n","Word2Vec is a foundational technique in NLP and has paved the way for more advanced embedding methods like GloVe (Global Vectors for Word Representation) and fastText. These techniques are crucial for understanding and processing natural language text in a wide range of applications\n","\n"]},{"cell_type":"markdown","source":["## gensim\n","\n","Gensim is an open-source Python library for natural language processing (NLP) and machine learning that focuses on text modeling and topic modeling. It was developed primarily for efficient and scalable topic modeling and document similarity analysis but has since grown to include various other features and functionalities related to text processing and modeling. Gensim is widely used by researchers, data scientists, and developers for working with large text corpora and performing tasks such as document similarity, topic modeling, and word embedding training.\n","\n","\n","**Reference**\n","- https://radimrehurek.com/gensim/auto_examples/\n","- https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html\n","\n"],"metadata":{"id":"utvfb17RU1P7"},"id":"utvfb17RU1P7"},{"cell_type":"code","execution_count":null,"id":"f587ebac-a34f-40c1-8a06-de540ae161e1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f587ebac-a34f-40c1-8a06-de540ae161e1","executionInfo":{"status":"ok","timestamp":1695407161853,"user_tz":-345,"elapsed":5037,"user":{"displayName":"Rupak Ghimire","userId":"14487243991408801434"}},"outputId":"95dd3a8e-1704-4b28-8ab3-1603c53f2783"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.2)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"]}],"source":["!pip install gensim numpy"]},{"cell_type":"code","execution_count":null,"id":"c04dcd41-d85a-473a-b107-5f3bf80a2838","metadata":{"id":"c04dcd41-d85a-473a-b107-5f3bf80a2838"},"outputs":[],"source":["import re\n","import nltk\n","import gensim\n","from gensim.models import word2vec"]},{"cell_type":"markdown","source":["### Step 1: Prepare Your Text Data\n","Before you can train a Word2Vec model, you need to prepare your text data. This includes cleaning and tokenizing your text. Here's a simple example:"],"metadata":{"id":"EdrXbWgtVmRf"},"id":"EdrXbWgtVmRf"},{"cell_type":"code","execution_count":null,"id":"1ce4d3b6-365b-4e18-a8d9-4fb8b35547f5","metadata":{"id":"1ce4d3b6-365b-4e18-a8d9-4fb8b35547f5"},"outputs":[],"source":["text = \"\"\"\n","The Russian state-owned energy giant, Gazprom, said the restrictions on the Nord Stream 1 pipeline would last for the next three days.\n","Russia has already significantly reduced gas exports via the pipeline.\n","It denies accusations it has used energy supplies as a weapon of war against Western countries.\n","The Nord Stream 1 pipeline stretches 1,200km (745 miles) under the Baltic Sea from the Russian coast near St Petersburg to north-eastern Germany.\n","It opened in 2011, and can send a maximum of 170 million cubic metres of gas per day from Russia to Germany.\n","\"\"\""]},{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WL3gs-Q8JIu5","executionInfo":{"status":"ok","timestamp":1695443899873,"user_tz":-345,"elapsed":1081,"user":{"displayName":"Rupak Ghimire","userId":"14487243991408801434"}},"outputId":"2637374b-6f94-4201-ec64-620ab85d32b3"},"id":"WL3gs-Q8JIu5","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","execution_count":null,"id":"ca359aa0-2537-4487-933d-fa6f95a36367","metadata":{"id":"ca359aa0-2537-4487-933d-fa6f95a36367"},"outputs":[],"source":["# all the stop words for all language\n","stop_words = nltk.corpus.stopwords.words('english')\n","# stop_words"]},{"cell_type":"code","execution_count":null,"id":"2f6c4f3c-4767-4184-98c7-0304c49a63ba","metadata":{"id":"2f6c4f3c-4767-4184-98c7-0304c49a63ba"},"outputs":[],"source":["def sentence_tokenize(text):\n","    punkt_tokenizer = nltk.tokenize.PunktSentenceTokenizer(text)\n","    tokenized = punkt_tokenizer.tokenize(text)\n","    return tokenized\n","\n","\n","def clean_text(text):\n","    # remove the numbers and remove stop words, non letters\n","    sentences = sentence_tokenize(text)\n","    tokens = []\n","    for sentence in sentences:\n","        new_tokens = nltk.tokenize.word_tokenize(sentence)\n","        # print(new_tokens)\n","        for word in new_tokens:\n","            if word in stop_words:\n","                new_tokens.remove(word)\n","        tokens = tokens + new_tokens\n","    return tokens"]},{"cell_type":"code","execution_count":null,"id":"6558ec26-a860-4035-9fd3-ba2574ce1243","metadata":{"tags":[],"id":"6558ec26-a860-4035-9fd3-ba2574ce1243"},"outputs":[],"source":["corpus = clean_text(text)\n","# corpus"]},{"cell_type":"markdown","source":["### Step 2: Train a Word2Vec Model\n","\n","Next, you'll train a Word2Vec model on your tokenized text data. You can configure various parameters, such as the vector dimensionality (`size`), window size (`window)`, and training algorithm (sg for `Skip-gram` or `cbow` for Continuous Bag of Words).\n","\n","\n","```\n","# Train a Word2Vec model\n","model = Word2Vec(\n","    tokenized_data,\n","    vector_size=100,  # Dimensionality of the word vectors\n","    window=5,          # Context window size\n","    min_count=1,       # Minimum word frequency to consider\n","    sg=0,              # Use CBOW (0) or Skip-gram (1)\n","    workers=4          # Number of CPU cores to use for training\n",")\n","```"],"metadata":{"id":"PINFwqpCVScH"},"id":"PINFwqpCVScH"},{"cell_type":"code","execution_count":null,"id":"4a99abaa-dd7e-42aa-8658-e7a869aa88be","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4a99abaa-dd7e-42aa-8658-e7a869aa88be","executionInfo":{"status":"ok","timestamp":1695444138789,"user_tz":-345,"elapsed":5,"user":{"displayName":"Rupak Ghimire","userId":"14487243991408801434"}},"outputId":"a840b608-ca5c-4ecd-bfab-61871be6236d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Word2Vec<vocab=63, vector_size=100, alpha=0.025>\n"]}],"source":["# model = word2vec.Word2Vec(corpus,vector_size=200,window=20, min_count=0, workers=4)\n","model = word2vec.Word2Vec([corpus], min_count=1)\n","# data = gensim.models.word2vec.LineSentence(filename)\n","print(model)"]},{"cell_type":"markdown","source":["### Step 3: Use the Word2Vec Model\n","\n","```\n","similar_words = model.wv.most_similar(\"document\", topn=5)\n","print(similar_words)\n","```"],"metadata":{"id":"hi-THomeV7xy"},"id":"hi-THomeV7xy"},{"cell_type":"code","execution_count":null,"id":"e4ebe908-cd93-4976-a51f-f0b5d5da590c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e4ebe908-cd93-4976-a51f-f0b5d5da590c","executionInfo":{"status":"ok","timestamp":1695444143834,"user_tz":-345,"elapsed":6,"user":{"displayName":"Rupak Ghimire","userId":"14487243991408801434"}},"outputId":"f4f08d39-d7f0-455b-afb8-84a8f553ebbd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.00949597,  0.00958518, -0.00776668, -0.00263947, -0.00490856,\n","       -0.00499557, -0.00801268, -0.0077347 , -0.00456166, -0.00129522,\n","       -0.00512872,  0.00612848, -0.0095164 , -0.00530883,  0.00945281,\n","        0.00697663,  0.00769548,  0.00422311,  0.00048875, -0.00599704,\n","        0.00602594,  0.00263872,  0.00772202,  0.00636618,  0.00792931,\n","        0.00865827, -0.00993999, -0.00675818,  0.0013466 ,  0.00645069,\n","        0.0074159 ,  0.00551455,  0.00768108, -0.0051468 ,  0.00657358,\n","       -0.00409449, -0.00903703,  0.00914577,  0.00130429, -0.00277189,\n","       -0.00246584, -0.00421045,  0.00481935,  0.00440827, -0.00265704,\n","       -0.00735463, -0.00356974, -0.00036105,  0.00609615, -0.00282682,\n","       -0.00011138,  0.00085623, -0.00711399,  0.00205407, -0.00146161,\n","        0.00280777,  0.00485327, -0.00134534, -0.00278401,  0.00774932,\n","        0.0050701 ,  0.00672746,  0.00454453,  0.00868534,  0.0074941 ,\n","       -0.00105813,  0.00875308,  0.00461585,  0.00538305, -0.00138998,\n","       -0.00205537, -0.00440954, -0.00848344,  0.0030357 ,  0.00890954,\n","        0.00890869, -0.00193769,  0.00608753,  0.00375291, -0.00429579,\n","        0.00201883, -0.00543997,  0.00818024,  0.00545896,  0.00316044,\n","        0.00408284,  0.00870023,  0.0072769 , -0.00083695, -0.00707916,\n","        0.00840369,  0.00723649,  0.00172753, -0.00134642, -0.00587067,\n","       -0.00453825,  0.00864299, -0.00311337, -0.00633116,  0.00986559],\n","      dtype=float32)"]},"metadata":{},"execution_count":11}],"source":["model.wv['Russia']"]},{"cell_type":"code","execution_count":null,"id":"08ea4b9d-0dd1-4bfc-ae03-63793d7cd25d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08ea4b9d-0dd1-4bfc-ae03-63793d7cd25d","executionInfo":{"status":"ok","timestamp":1695444230820,"user_tz":-345,"elapsed":11,"user":{"displayName":"Rupak Ghimire","userId":"14487243991408801434"}},"outputId":"a75efd73-914b-4693-b463-9511d957338f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Similarity between 'weapon' and 'war': 0.15172634\n"]}],"source":["similarity = model.wv.similarity(\"weapon\", \"war\")\n","print(\"Similarity between 'weapon' and 'war':\", similarity)"]},{"cell_type":"code","execution_count":null,"id":"d927ce7f-9c9f-4754-922a-3c80b4e5a42a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d927ce7f-9c9f-4754-922a-3c80b4e5a42a","executionInfo":{"status":"ok","timestamp":1695444218830,"user_tz":-345,"elapsed":397,"user":{"displayName":"Rupak Ghimire","userId":"14487243991408801434"}},"outputId":"dca277d5-ec08-4b67-ace8-252f3baa8e6a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('via', 0.18393656611442566),\n"," ('significantly', 0.167282834649086),\n"," ('.', 0.14069588482379913),\n"," ('last', 0.13259515166282654),\n"," ('energy', 0.12228170782327652),\n"," ('Russian', 0.11194396018981934),\n"," ('1', 0.09922793507575989),\n"," ('supplies', 0.08814319968223572),\n"," ('It', 0.08411835879087448),\n"," ('would', 0.0820133239030838)]"]},"metadata":{},"execution_count":15}],"source":["model.wv.most_similar('countries', topn=10)"]},{"cell_type":"markdown","source":["### Step 4: Save and Load a trained Model"],"metadata":{"id":"OXkNHkhGWyGN"},"id":"OXkNHkhGWyGN"},{"cell_type":"code","execution_count":null,"id":"01927a09-351f-42f1-9af7-f0ccec3733b4","metadata":{"id":"01927a09-351f-42f1-9af7-f0ccec3733b4"},"outputs":[],"source":["model.save('model.bin')"]},{"cell_type":"code","execution_count":null,"id":"e9f141a6-fc2a-4a8d-8a00-bf05f1d42132","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e9f141a6-fc2a-4a8d-8a00-bf05f1d42132","executionInfo":{"status":"ok","timestamp":1695444339794,"user_tz":-345,"elapsed":7,"user":{"displayName":"Rupak Ghimire","userId":"14487243991408801434"}},"outputId":"0c45a755-5ead-4076-cb2c-996ec2a204d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Word2Vec<vocab=63, vector_size=100, alpha=0.025>\n"]}],"source":["# # load model\n","new_model = word2vec.Word2Vec.load('model.bin')\n","print(new_model)"]},{"cell_type":"code","execution_count":null,"id":"95f7b60f-a96a-4d9c-b636-768fdc9dd1a6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"95f7b60f-a96a-4d9c-b636-768fdc9dd1a6","executionInfo":{"status":"ok","timestamp":1695444352100,"user_tz":-345,"elapsed":6,"user":{"displayName":"Rupak Ghimire","userId":"14487243991408801434"}},"outputId":"623bb2f6-c60f-4273-9694-207b400a1319"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('via', 0.18393656611442566),\n"," ('significantly', 0.167282834649086),\n"," ('.', 0.14069588482379913),\n"," ('last', 0.13259515166282654),\n"," ('energy', 0.12228170782327652),\n"," ('Russian', 0.11194396018981934),\n"," ('1', 0.09922793507575989),\n"," ('supplies', 0.08814319968223572),\n"," ('It', 0.08411835879087448),\n"," ('would', 0.0820133239030838)]"]},"metadata":{},"execution_count":19}],"source":["new_model.wv.most_similar('countries', topn=10)"]},{"cell_type":"markdown","id":"3c4cf1c9-b918-4b5e-bf91-1a8d4447c07a","metadata":{"id":"3c4cf1c9-b918-4b5e-bf91-1a8d4447c07a"},"source":["## Other example"]},{"cell_type":"code","execution_count":null,"id":"0f9df30e-159c-491c-81c0-d55d4e2a366f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0f9df30e-159c-491c-81c0-d55d4e2a366f","executionInfo":{"status":"ok","timestamp":1695407271526,"user_tz":-345,"elapsed":5,"user":{"displayName":"Rupak Ghimire","userId":"14487243991408801434"}},"outputId":"e6e47480-a1d5-46bb-b2e0-1b440ddc89aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["[['Cake', 'is', 'a', 'form', 'of', 'sweet', 'food', 'made', 'from', 'flour', ',', 'sugar', ',', 'and', 'other', 'ingredients', ',', 'that', 'is', 'usually', 'baked', '.'], ['In', 'their', 'oldest', 'forms', ',', 'cakes', 'were', 'modifications', 'of', 'bread', ',', 'but', 'cakes', 'now', 'cover', 'a', 'wide', 'range', 'of', 'preparations', 'that', 'can', 'be', 'simple', 'or', 'elaborate', ',', 'and', 'that', 'share', 'features', 'with', 'other', 'desserts', 'such', 'as', 'pastries', ',', 'meringues', ',', 'custards', ',', 'and', 'pies', '.']]\n","Word2Vec<vocab=48, vector_size=100, alpha=0.025>\n"]},{"output_type":"execute_result","data":{"text/plain":["array([-8.7274825e-03,  2.1301615e-03, -8.7354420e-04, -9.3190884e-03,\n","       -9.4281426e-03, -1.4107180e-03,  4.4324086e-03,  3.7040710e-03,\n","       -6.4986930e-03, -6.8730675e-03, -4.9994122e-03, -2.2868442e-03,\n","       -7.2502876e-03, -9.6033178e-03, -2.7436293e-03, -8.3628409e-03,\n","       -6.0388758e-03, -5.6709289e-03, -2.3441375e-03, -1.7069972e-03,\n","       -8.9569986e-03, -7.3519943e-04,  8.1525063e-03,  7.6904297e-03,\n","       -7.2061159e-03, -3.6668312e-03,  3.1185520e-03, -9.5707225e-03,\n","        1.4764392e-03,  6.5244664e-03,  5.7464195e-03, -8.7630618e-03,\n","       -4.5171441e-03, -8.1401607e-03,  4.5956374e-05,  9.2636338e-03,\n","        5.9733056e-03,  5.0673080e-03,  5.0610625e-03, -3.2429171e-03,\n","        9.5521836e-03, -7.3564244e-03, -7.2703874e-03, -2.2653891e-03,\n","       -7.7856064e-04, -3.2161034e-03, -5.9258583e-04,  7.4888230e-03,\n","       -6.9751858e-04, -1.6249407e-03,  2.7443992e-03, -8.3591007e-03,\n","        7.8558037e-03,  8.5361041e-03, -9.5840869e-03,  2.4462664e-03,\n","        9.9049713e-03, -7.6658037e-03, -6.9669187e-03, -7.7365171e-03,\n","        8.3959233e-03, -6.8133592e-04,  9.1444086e-03, -8.1582209e-03,\n","        3.7430846e-03,  2.6350426e-03,  7.4271322e-04,  2.3276759e-03,\n","       -7.4690939e-03, -9.3583735e-03,  2.3545765e-03,  6.1484552e-03,\n","        7.9856887e-03,  5.7358947e-03, -7.7733636e-04,  8.3061643e-03,\n","       -9.3363142e-03,  3.4061326e-03,  2.6675343e-04,  3.8572443e-03,\n","        7.3857834e-03, -6.7251669e-03,  5.5844807e-03, -9.5222248e-03,\n","       -8.0445886e-04, -8.6887367e-03, -5.0986730e-03,  9.2892265e-03,\n","       -1.8582619e-03,  2.9144264e-03,  9.0712793e-03,  8.9381328e-03,\n","       -8.2084350e-03, -3.0123137e-03,  9.8866057e-03,  5.1044310e-03,\n","       -1.5880871e-03, -8.6920215e-03,  2.9615164e-03, -6.6758976e-03],\n","      dtype=float32)"]},"metadata":{},"execution_count":17}],"source":["from gensim.models import Word2Vec\n","import nltk\n","# define training data\n","content=\"\"\"Cake is a form of sweet food made from flour, sugar, and other ingredients, that is usually baked.\n","In their oldest forms, cakes were modifications of bread, but cakes now cover a wide range of preparations that can be simple or elaborate, and that share features with other desserts such as pastries, meringues, custards, and pies.\"\"\"\n","sentences=nltk.sent_tokenize(content)\n","words=[]\n","\n","for i in sentences:\n","    words.append(nltk.word_tokenize(i))\n","\n","# train model\n","print(words)\n","model = Word2Vec(words, min_count=1)\n","\n","# summarize the loaded model\n","print(model)\n","\n","# summarize vocabulary\n","# word_vec_words = list(model.wv)\n","# print(word_vec_words)\n","\n","# access vector for one word\n","# print(model['sugar'])\n","model.wv['is']\n","# # save model\n","# model.save('model.bin')\n","\n","# # load model\n","# new_model = Word2Vec.load('model.bin')\n","# print(new_model)\n"]},{"cell_type":"code","execution_count":null,"id":"79ae4c99-34d7-4b7a-812b-29d711d87345","metadata":{"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"79ae4c99-34d7-4b7a-812b-29d711d87345","executionInfo":{"status":"ok","timestamp":1695407280396,"user_tz":-345,"elapsed":368,"user":{"displayName":"Rupak Ghimire","userId":"14487243991408801434"}},"outputId":"1bd0a601-d116-44de-ae55-5536335d8a1c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('form', 0.1960250288248062),\n"," ('desserts', 0.1585622876882553),\n"," ('of', 0.12292061746120453),\n"," ('share', 0.10217307507991791),\n"," ('can', 0.08713015913963318)]"]},"metadata":{},"execution_count":18}],"source":["model.wv.most_similar('sugar', topn=5)"]},{"cell_type":"code","execution_count":null,"id":"6f2ec278-e9c7-4f08-b9fa-b385fadd2488","metadata":{"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"6f2ec278-e9c7-4f08-b9fa-b385fadd2488","executionInfo":{"status":"ok","timestamp":1695407283542,"user_tz":-345,"elapsed":5,"user":{"displayName":"Rupak Ghimire","userId":"14487243991408801434"}},"outputId":"d2e00e4d-302b-46c5-e906-d9c1e5110e47"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('bread', 0.14504408836364746),\n"," ('but', 0.14474980533123016),\n"," ('share', 0.12842437624931335),\n"," ('their', 0.12143993377685547),\n"," ('other', 0.10018284618854523),\n"," ('baked', 0.09942895919084549),\n"," ('sweet', 0.09211055934429169),\n"," ('sugar', 0.08713015168905258),\n"," ('such', 0.08693084120750427),\n"," ('Cake', 0.08146469295024872)]"]},"metadata":{},"execution_count":19}],"source":["model.wv.most_similar('can', topn=10)"]},{"cell_type":"markdown","id":"a785d6e7-bba9-4cbc-bf85-e83a6c269168","metadata":{"id":"a785d6e7-bba9-4cbc-bf85-e83a6c269168"},"source":["# Urdu wav2vec\n","\n","Ref: https://github.com/samarh/urduvec\n","\n","Download the model into the workspace\n","https://drive.google.com/u/0/uc?id=1K_4Fbdv9GJDNjR_avLbzKdJPEMVWdYBm&export=download\n"]},{"cell_type":"code","execution_count":null,"id":"6b018d1d-cba3-4e85-8dfe-1985aa8a26ff","metadata":{"id":"6b018d1d-cba3-4e85-8dfe-1985aa8a26ff"},"outputs":[],"source":["pip install --upgrade gensim"]},{"cell_type":"code","execution_count":null,"id":"79a1ebac-ec49-4f2c-8903-a7c5843a54c9","metadata":{"id":"79a1ebac-ec49-4f2c-8903-a7c5843a54c9"},"outputs":[],"source":["from gensim.models import word2vec\n","\n","# import the existing module\n","urdu_model = word2vec.Word2Vec.load_word2vec_format('urduvec_140M_100K_300d.bin', binary=True)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"colab":{"provenance":[{"file_id":"1wvcys75pW-4IQk0lrLK7Vp8y5UAcoQYC","timestamp":1695444441434}]}},"nbformat":4,"nbformat_minor":5}